{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da81fc8",
   "metadata": {},
   "source": [
    "### Raw basics\n",
    "Some under-the-hood for building intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1305d19c",
   "metadata": {},
   "source": [
    "##### Basic Neuron\n",
    "\n",
    "              ┌─────────────────────────────────────────────┐\n",
    "              │               Neuron                        │                                              \n",
    "              │                                             │\n",
    "  Inputs      │     Weights         Computation             │    Output\n",
    "              │                                             │\n",
    "   x₁ = 0.5 ──┼──>  w₁ = 0.2 ──┐                            │\n",
    "              │                │                            │\n",
    "   x₂ = 1.0 ──┼──>  w₂ = 0.8 ──┼─► z = Σ(wᵢxᵢ) + b          │\n",
    "              │                │    = 0.2×0.5 + 0.8×1.0     │\n",
    "   x₃ = 0.3 ──┼──>  w₃ = -0.1 ─┤    + (-0.1)×0.3 + 0.5      │\n",
    "              │                │    = 0.1 + 0.8 - 0.03 + 0.5│       ┌─────┐\n",
    "              │                │    = 1.37                  ├───►   │ 1   │  = 0.798\n",
    "              │                │                            │       │─────│\n",
    "              │     bias = 0.5 ┘                            │       │1+e⁻ᶻ│\n",
    "              │                                             │       └─────┘\n",
    "              └─────────────────────────────────────────────┘       Activation Function \n",
    "                                                                    \n",
    "Sigmoid Activation Function\n",
    "                                                                      \n",
    "  1 │       ---------------------\n",
    "    │      /              │\n",
    "    │     /               │\n",
    "    │    /                │\n",
    "y   │   /                 │\n",
    "    │  /                  │\n",
    "    │ /                   │\n",
    "  0 │/                    │\n",
    "    └---------------------|------->\n",
    "    -6      0      z      6\n",
    "           Input value\n",
    "\n",
    "A Neuron..\n",
    "* Takes multiple inputs (x₁, x₂, x₃, ...)\n",
    "* Multiplies each by its corresponding weight (w₁, w₂, w₃, ...)\n",
    "* Sums these products + bias value\n",
    "* Passes this sum through an activation function (sigmoid)\n",
    "* Out falls a single output value between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbf716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, num_inputs):\n",
    "        self.weights = [random.uniform(-1, 1) for _ in range(num_inputs)]\n",
    "        self.bias = random.uniform(-1, 1)\n",
    "    \n",
    "    def activate(self, inputs):\n",
    "        weighted_sum = sum(w * x for w, x in zip(self.weights, inputs)) + self.bias\n",
    "        return self.sigmoid(weighted_sum)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b164e1",
   "metadata": {},
   "source": [
    "### Basic Layer\n",
    "* All neurons in the layer receive the same inputs \n",
    "* Each neuron has its own set of weights and bias\n",
    "* Each neuron processes the inputs independently\n",
    "* The layer produces multiple outputs, one from each neuron (See Neuron.activate () )\n",
    "* forward() collects all outputs into a list and returns it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "429d55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, num_neurons, num_inputs_per_neuron):\n",
    "        self.neurons = [Neuron(num_inputs_per_neuron) for _ in range(num_neurons)]\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        outputs = [neuron.activate(inputs) for neuron in self.neurons]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c0d0d6",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "Stack layers together, here information flows from inputs -> hidden layer -> output layer\n",
    "\n",
    "Forward Propagation Process:\n",
    "\n",
    "Step 1: inputs --> hidden layer:\n",
    "   For each hidden neuron j:\n",
    "        h_j = sigmoid(sum(w_ji × x_i) + b_j)\n",
    "   \n",
    "   where:\n",
    "   - x_i are the inputs\n",
    "   - w_ji are weights from input i to hidden neuron j\n",
    "   - b_j is the bias of hidden neuron j\n",
    "   - h_j is the output of hidden neuron j\n",
    "\n",
    "Step 2: hidden layer --> output layer:\n",
    "   For each output neuron k:\n",
    "        y_k = sigmoid(sum(w_kj × h_j) + b_k)\n",
    "   \n",
    "   where:\n",
    "   - h_j are the hidden layer outputs\n",
    "   - w_kj are weights from hidden neuron j to output neuron k\n",
    "   - b_k is the bias of output neuron k\n",
    "   - y_k is the final output of neuron k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d23c93b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        # input2hidden layer\n",
    "        self.hidden_layer = Layer(num_hidden, num_inputs)\n",
    "        # hidden2output layer\n",
    "        self.output_layer = Layer(num_outputs, num_hidden)\n",
    "\n",
    "    def forward (self, inputs):\n",
    "        hidden_outputs = self.hidden_layer.forward(inputs)\n",
    "        return self.output_layer.forward(hidden_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
